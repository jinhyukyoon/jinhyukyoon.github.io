<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Jinhyuk Yoon's Portfolio Page">
  <meta name="author" content="Jinhyuk Yoon">

  <meta property="og:title" content="Jinhyuk Yoon" />
  <meta property="og:description" content="Jinhyuk Yoon" />
  <meta property="og:image" content="./img/metaimage.jpg" />

  <title>Jinhyuk Yoon | Work</title>

  <!-- Bootstrap core CSS -->
  <link href="./vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Bootstrap core JavaScript -->
  <script src="./vendor/jquery/jquery.min.js"></script>
  <script src="./vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Custom styles for this template -->
  <link href="./css/main.css" rel="stylesheet">
  <script src="./js/main.js"></script>

</head>


<body>

  <!-- Navigator -->
  <nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand" href="./index.html">JinHyuk Yoon</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="./projects.html">project</a>
          </li>
          <li class="nav-item">
            <a class="nav-link active" href="#">work</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>


  <!-- Work content -->

  <section>

    <div class="container padding-bottom-100px">
      <div class="row row-head">
        <div class="col-md-12 ">


<!--
          <div class="row work-row-top">
            <div class="col-md-8 order-md-2">
              <div class="card">
                <a href="" data-toggle="modal" data-target="#popup-1dofcdhi">
                  <img class="card-img-top" src="./img/work/1dofcdhi1.jpg" alt="">
                </a>
              </div>
            </div>
            <div class="col-md-4 work-contents order-md-1">
              <span class="work-bold-title "> Cable-driven Haptic Interface with Inertia Reshaping <br></span>
              <p class="work-description text-left">
                Haptic interface for remote embodied learning sceanario</p>
              <div class="work-contents-date">2021</div>
            </div>
          </div>

          <div id="popup-1dofcdhi" class="modal fade" role="dialog" tabindex="-1">
            <div class="modal-dialog work-contents modal-lg">
              <div class="modal-content">
                <div class="modal-header">
                  <h4 class="modal-title">Cable-driven Haptic Interface with Inertia Reshaping</h4>
                  <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                </div>
                <div class="modal-body">
                  <font color="gray">My role: system setup, controller implementation, user experiment design & proceeding
                    <br>Collaborator: Sejin Kim, Donghyeon Lee<br>
                    Advisor: Keehoon Kim<br></font><br>
                    In the era of a pandemic, online learning is becoming popular as the future of education.
                    While physical interaction takes an important role in education for embodied learning, there is still a lack of haptic information in the remote classroom.
                  <div class="row">
                    <div class="col-lg-12">
                      <img class="img-fluid mx-auto d-block rounded" src="./img/work/1dofcdhi2.jpg">
                    </div>
                  </div>
                  In this study, a cable-driven haptic device that can display variable impedance is proposed to provide haptic interaction in the remote education environment.
                  The proposed haptic interface displays very low inertia for very light object motion in the virtual environment overcoming the inherent mechanical inertia due to motors and transmission via the proposed inertia reshaping controller.
                  <div class="row">
                    <div class="col-lg-12">
                      <img class="img-fluid mx-auto d-block rounded" src="./img/work/1dofcdhi3.jpg">
                    </div>
                  </div>

                  The controller could reduce the effective inertia of the system to 6.12% of experimentally measured inertia.
                  <div class="row">
                    <div class="col-lg-12">
                      <img class="img-fluid mx-auto d-block rounded" src="./img/work/1dofcdhi4.jpg">
                    </div>
                  </div>

                  In addition, a user experiment was conducted to verify the usability of the interface for remote embodied learning.
                  In 98.67% of 150 trials, the subjects successfully distinguished five virtual objects of different inertia under the learning scenario of Newton’s first law of motion.


                </div>
              </div>
            </div>
          </div>

-->

          <div class="row work-row-top">
            <div class="col-md-8 order-md-2">
              <div class="card">
                <a href="" data-toggle="modal" data-target="#popup-apb">
                  <img class="card-img-top" src="./img/work/apb1.png" alt="">
                </a>
              </div>
            </div>
            <div class="col-md-4 work-contents order-md-1">
              <span class="work-bold-title "> Augmenting Physical Buttons <br></span>
              <p class="work-description text-left">
                Providing programmable feels with vibrotactile feedback</p>
              <div class="work-contents-date">2019</div>
            </div>
          </div>

          <div id="popup-apb" class="modal fade" role="dialog" tabindex="-1">
            <div class="modal-dialog work-contents modal-lg">
              <div class="modal-content">
                <div class="modal-header">
                  <h4 class="modal-title">Augmenting Physical Buttons</h4>
                  <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                </div>
                <div class="modal-body">
                  <font color="gray">My role: hardware prototyping, sensing system design
                    <br>Collaborator: Chaeyong park, Seungjae Oh<br>
                    Advisor: Seungmoon Choi<br></font><br>
                  Physical buttons provide clear haptic feedback when pressed and released, but their responses are unvarying.
                  Physical buttons can be powered by force actuators to produce unlimited click sensations, but the cost is substantial.
                  <div class="row">
                    <div class="col-lg-12">
                      <img class="img-fluid mx-auto d-block rounded" src="./img/work/apb2.png">
                    </div>
                  </div>
                  We address a novel alternative: augmenting physical buttons with additional vibration.
                  When pushed, an augmented button generates a vibration using a simple actuator overlayed on the button’s original kinesthetic response, under the general framework of haptic augmented reality.<br>
                  <div class="row">
                    <div class="col-lg-12">
                      <img class="img-fluid mx-auto d-block rounded" src="./img/work/apb3.png">
                    </div>
                  </div>
                  We explore the design space of augmented buttons while changing vibration frequency, amplitude, duration, and envelope.
                  We then visualize the perceptual structure of augmented buttons by estimating a perceptual space for 7 physical buttons and 40 augmented buttons.
                  Their sensations are also assessed against adjectives, and results are mapped into the perceptual space to identify meaningful perceptual dimensions.
                  <div class="row">
                    <div class="col-lg-12">
                      <img class="img-fluid mx-auto d-block rounded" src="./img/work/apb4.png">
                    </div>
                  </div>
                  Our results contribute to understanding the benefits and limitations of programmable vibration-augmented physical buttons with emphasis on their feels.
                </div>
              </div>
            </div>
          </div>

          <div class="row work-row-sub">
            <div class="col-md-8 order-md-2">
              <div class="card">
                <a href="" data-toggle="modal" data-target="#popup-itd">
                  <img class="card-img-top" src="./img/work/itd1.jpg" alt="">
                </a>
              </div>
            </div>
            <div class="col-md-4 work-contents order-md-1">
              <span class="work-bold-title "> Interactive Torque Designer <br></span>
              <p class="work-description text-left">
                Dynamic analysis through graphic interaction</p>
              <div class="work-contents-date">2019</div>
            </div>
          </div>

          <div id="popup-itd" class="modal fade" role="dialog" tabindex="-1">
            <div class="modal-dialog work-contents modal-lg">
              <div class="modal-content">
                <div class="modal-header">
                  <h4 class="modal-title">Interactive Torque Designer</h4>
                  <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                </div>
                <div class="modal-body">
                  <font color="gray">My role: dynamic analysis, application development
                    <br>Advisor: Geonhee Lee, Wangi Park, Junwon Seo, Dr. Yongsoo Kyong<br></font><br>
                  Dynamic analysis of hinge takes important part on developing digital oven.
                  Traditional method that uses a computational simulation software, however, takes complicated manipulation process.
                  Hence, it cannot provide reverse engineering, which modifies dynaimc property through setting a desirable torque profile.
                  Interactive Torque Designer solves these problems through dynamic analysis and web application which even enables interactive design with graphical modification.<br>
                  <div class="row">
                    <div class="col-lg-12">
                      <img class="img-fluid rounded" src="./img/work/itd2.gif">
                    </div>
                  </div>
                  Web application has universality and scalability.
                  Any user can use this application only with internet browser and adapting additional function requires just simple programming.
                  Using d3.js library, plotted data enables to reflect dynamic analysis result graphically.
                  Consequently, user can get torque profile directly only with dragging cam profile and vice versa without heavy simulation.
                  <div class="row">
                    <div class="col-lg-12">
                      <img class="img-fluid rounded" src="./img/work/itd3.gif">
                    </div>
                  </div>
                  Direct user experience feedbacks of field engineers according to iterative design process suggests multiple drag and other functions which make design process more easily.
                  With the final version of Interactive Torque Designer, user can intuitively analyze torque and do the inverse engineering, which significantly simplifies mechanical design process of digital oven.
                  Furthermore, it helps engineer to explain with other division member as explaining mechanical phenomenon through graphic expression without professional knowledge.
                </div>
              </div>
            </div>


          </div>
        </div>
      </div>

      <div class="row row-head">
        <div class="col-md-12 work-title">
          Exploration
        </div>

        <div class="col-md-4 exploration">
          <div class="card exploration">
            <a href="" data-toggle="modal" data-target="#popup-sovoro">
              <img class="card-img-top exploration" src="./img/work/sovoro.jpg" alt="">
            </a>
          </div>
          <span class="work-bold-title "> Sovoro <br></span>
          <p class="work-description text-left">
            Auto transcription software for people with hearing loss
          </p>
          <div class="work-contents-date exploration">2018</div>
        </div>

        <div id="popup-sovoro" class="modal fade" role="dialog" tabindex="-1">
          <div class="modal-dialog work-contents modal-lg">
            <div class="modal-content">
              <div class="modal-header">
                <h4 class="modal-title">Sovoro</h4>
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
              </div>
              <div class="modal-body">
                <font color="gray">My role: UI/UX research & design, market research, business activity, catalog design
                  <br>Collaborator: Jihyeon Yoon, Seungman Choi, and Yongtaek Kwon<br></font><br>
                Sovoro develops auto transcription software using real-time speech-to-text voice recognition engine as a social start-up.
                Service targets people with hearing loss who want to take usual on/offline class or seminar.
                Since existing solutions, such as stenography or sign language, failed to satisfy with this need because of expensive cost and inefficiency for
                daily usage, Sovoro improves educational circumstance of people with hearing loss as overcoming these problems through viable software.<br>
                <div class="video-container">
                  <iframe id="player" width="854" height="480" src="https://www.youtube.com/embed/PLdRVMsAFYc?rel=0&showinfo=0&controls=1" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div>
                Proposed user interface and user experience as a communication manager focused on showing transcript in a clear way. Minimizing menu buttons and always-on-top script panel are naturally followed in this manner.
                Additionally, user can modify font size, transparency, language through setting.
                <div class="row">
                  <div class="col-lg-6">
                    <img class="img-fluid rounded" src="./img/work/sovoro1.jpg">
                  </div>
                  <div class="col-lg-6">
                    <img class="img-fluid rounded" src="./img/work/sovoro2.jpg">
                  </div>
                </div>
                First prototype only focused on internal sound of computer for online class or seminar. However, several interviews about user interface and user experience with people who have hearing loss suggest another need about external
                sound of computer.
                Therefore, adding external mic, which is portable, wireless, and reasonable in operating distance, expands function of software to cover offline lecture, business interview, or daily talk.<br><br>
                Developed software with iterative design process made contracts with Korea Employment Agency for the Disabled, university, and center for people of hearing loss to provide educational assistance.
                Furthermore, software and result of contract bridged to 30 million Won seed funding and accelerating of Sopoong, a social venture accelerator.
              </div>
            </div>
          </div>
        </div>


        <div class="col-md-4 exploration">
          <div class="card exploration">
            <a href="" data-toggle="modal" data-target="#popup-grad">
              <img class="card-img-top exploration" src="./img/work/grad1.jpg" alt="">
            </a>
          </div>
          <span class="work-bold-title "> Book Borrowing Robot <br></span>
          <p class="work-description text-left">
            Supporting book borrowing process in the library
          </p>
          <div class="work-contents-date exploration">2017</div>
        </div>

        <div id="popup-grad" class="modal fade" role="dialog" tabindex="-1">
          <div class="modal-dialog work-contents modal-lg">
            <div class="modal-content">
              <div class="modal-header">
                <h4 class="modal-title">Book Borrowing Robot</h4>
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
              </div>
              <div class="modal-body">
                <font color="gray">My role: software development, presentation
                  <br>Collaborator: Youngsin Kim, Sehwan Rho, Doohee Kim, and Donghyeon Lim </font><br><br>
                When users want to find a book in the library, they have to search book, find location of the specific bookshelves, and take it to the machine to proceed borrowing process.
                As bachelor thesis project, my team proposed Book Borrowing Robot to make book borrowing process automative and much easier.
                <div class="video-container">
                  <iframe width="640" height="360" src="https://www.youtube.com/embed/8Nx9ucGW0kA?rel=0&autoplay=1&loop=1&playlist=8Nx9ucGW0kA&controls=0&modestbranding=1&showinfo=0" frameborder="0" allow="autoplay; encrypted-media"
                    allowfullscreen></iframe>
                </div>
                Robot has gripper, camera, 3 number of microcontroller units, and motors.
                With information of bookshelf coordination, robot performs automatic driving to near the bookshelf with given map information.
                After performing precise driving with camera vision control until specific distance.
                Finally, robot drags book with gripper and rewinds previous driving process to bring it back to the user.
                <div class="row">
                  <div class="col-lg-6">
                    <img class="img-fluid rounded" src="./img/work/grad2.gif" style="width: 360.6px; height: 245.925px;">
                  </div>
                  <div class="col-lg-6">
                    <img class="img-fluid rounded" src="./img/work/grad3.gif">
                  </div>
                </div>
                Implementing mapping algorithm and vision control system enables automatic driving and precision driving until camera captures QR code each.
                Presentation of the project as the representative of the team successfully delivered contents.
              </div>
            </div>
          </div>
        </div>


        <div class="col-md-4 exploration">
          <div class="card exploration">
            <a href="" data-toggle="modal" data-target="#popup-amc">
              <img class="card-img-top exploration" src="./img/work/amc1.jpg" alt="">
            </a>
          </div>
          <span class="work-bold-title "> Ankle Rehabilitation Assistant <br></span>
          <p class="work-description text-left">
            Analyzing ankle torque and providing rehabilitative movement
          </p>
          <div class="work-contents-date exploration">2017</div>
        </div>

        <div id="popup-amc" class="modal fade" role="dialog" tabindex="-1">
          <div class="modal-dialog work-contents modal-lg">
            <div class="modal-content">
              <div class="modal-header">
                <h4 class="modal-title">Ankle Rehabilitation Assistant</h4>
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
              </div>
              <div class="modal-body">
                <font color="gray">My role: research, software & hardware development
                  <br>Advisor: Dr. Youngjin Moon</font><br><br>
                Biomedical Engineering Research Center of Asan Medical Center conducted various research such as catheter controller and lower body rehabilitation assistant equipment.
                Individual project aims to develop prototype of ankle rehabilitation assistant which can provide not only ankle torque but also rehabilitative movement for the patients.
                <div class="row">
                  <div class="col-lg-12">
                    <img class="img-fluid mx-auto d-block rounded" src="./img/work/amc2.jpg">
                  </div>
                </div>
                User can wear equipment using two straps positioned on thigh and foot.
                Equiment functions in two ways; analysis and movement mode.
                For analysis mode, force-sensing resistor analyze force and microcontroller unit calculates ankle torque with given mechanical structure data as user rotates his/her ankle.
                During movement mode, user puts information of maximum rotation angle as moving his/her ankle.
                Then microcontroller unit saves that information and repeat it using linear actuator.
                Equipment can provide rehabilitative movement for the user using this mode.
              </div>
            </div>
          </div>
        </div>




      </div>
    </div>
    </div>
    <!-- Exploration -->

  </section>


</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119550312-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }
  gtag('js', new Date());

  gtag('config', 'UA-119550312-1');



  $(".modal").on('hide.bs.modal', function(e) {
    $('iframe').each(function() {
      var src = $(this).attr('src');

      $(this).attr('src', src);
    });
  });
</script>


</html>
